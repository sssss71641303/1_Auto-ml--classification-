{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自動化機器學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用scikit-learn的[數字數據集]（http://scikit-learn.org/stable/datasets/index.html#optical-recognition-of-handwriting-digits-dataset）展示如何使用 AutoML用於簡單的分類問題。\n",
    "\n",
    "1.在現有的“工作區”中創建一個“實驗”。\n",
    "2.使用“ AutoMLConfig”配置AutoML。\n",
    "3.使用本地計算訓練模型。\n",
    "4.探索結果。\n",
    "5.測試最佳擬合模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Class\n",
    "\n",
    "作為安裝的一部分，已經創建了一個Azure ML Workspace對象。 \n",
    "對於AutoML，需要創建一個Experiment對象，該對像是工作區中用於運行實驗的命名對象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訪問Azure ML工作區需要使用Azure進行身份驗證。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# Choose a name for the experiment and specify the project folder.\n",
    "experiment_name = 'automl-classification'\n",
    "project_folder = './sample_projects/automl-classification'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace Name'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Project Directory'] = project_folder\n",
    "output['Experiment Name'] = experiment.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料來源\n",
    "\n",
    "使用scikit-learn的load_digits方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "# Exclude the first 100 rows from training so that they can be used for test.\n",
    "X_train = digits.data[100:,:]\n",
    "y_train = digits.target[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "實例化一個AutoMLConfig object以指定用於運行實驗的設置和數據。\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|classification or regression|\n",
    "|**primary_metric主要的指標**|要優化的指標。 分類支持以下主要指標: <br><i>accuracy</i><br><i>AUC_weighted</i><br><i>average_precision_score_weighted</i><br><i>norm_macro_recall</i><br><i>precision_score_weighted</i>|\n",
    "|**X**|(sparse) array-like, shape = [n_samples, n_features]|\n",
    "|**y**|(sparse) array-like, shape = [n_samples, ], Multi-class targets.|\n",
    "|**n_cross_validations**|Number of cross validation splits.|\n",
    "|\n",
    "\n",
    "自動化機器學習可訓練多個機器學習管道。 每次管道訓練都稱為iteration迭代(要執行訓練檔幾次)。\n",
    "\n",
    "您可以使用迭代參數指定最大迭代次數。\n",
    "您可以使用experiment_timeout_minutes參數指定運行的最長時間。\n",
    "如果您既未指定迭代次數，也未指定experiment_timeout_minutes，則自動ML將繼續運行迭代，同時繼續查看分數的提高。\n",
    "以下示例未指定迭代次數或experiment_timeout_minutes，因此一直運行直到分數不再提高。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不指定訓練幾次(最大迭代次數)也不指定運行的最長時間，一直運行直到分數不再提高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             primary_metric = 'AUC_weighted',\n",
    "                             X = X_train, \n",
    "                             y = y_train,\n",
    "                             n_cross_validations = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在實驗 object 上調用Submit方法並傳遞運行的config。 本機運行的執行是同步的。 根據數據和迭代次數，這可能會運行一段時間。\n",
    "在此示例中，我們指定show_output = True以將當前正在運行的迭代輸出到控制台。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_run = experiment.submit(automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通過調用不帶迭代參數的continue_experiment繼續中斷的本地運行，或者通過指定迭代參數為完成的運行運行更多的迭代："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_run = local_run.continue_experiment(X = X_train, \n",
    "                                          y = y_train, \n",
    "                                          show_output = True,\n",
    "                                          iterations = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用有指定最大迭代次數以及最大運行時間的config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_d33cf7ad-fc0a-4122-92e4-06a5397b844d\n",
      "Current status: DatasetCrossValidationSplit. Generating CV splits.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   StandardScalerWrapper SGD                      0:01:29       0.9941    0.9941\n",
      "         1   StandardScalerWrapper SGD                      0:01:30       0.9970    0.9970\n"
     ]
    }
   ],
   "source": [
    "automated_ml_config = AutoMLConfig(task = 'classification',\n",
    "                             primary_metric = 'AUC_weighted',\n",
    "                             X = X_train, \n",
    "                             y = y_train,\n",
    "                             n_cross_validations = 3,\n",
    "                             iterations=2,\n",
    "                             iteration_timeout_minutes=5)\n",
    "\n",
    "\n",
    "run = experiment.submit(automated_ml_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 檢索所有子運行\n",
    "還可以使用SDK方法獲取所有子運行，並查看我們記錄的各個指標。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC_macro</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_micro</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_weighted</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_macro</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_micro</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_weighted</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_macro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_micro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_weighted</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_macro_recall</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_macro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_micro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_weighted</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_macro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_micro</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_weighted</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_accuracy</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0    1\n",
       "AUC_macro                        0.99 1.00\n",
       "AUC_micro                        0.99 1.00\n",
       "AUC_weighted                     0.99 1.00\n",
       "accuracy                         0.95 0.96\n",
       "average_precision_score_macro    0.98 0.99\n",
       "average_precision_score_micro    0.98 0.99\n",
       "average_precision_score_weighted 0.98 0.99\n",
       "balanced_accuracy                0.95 0.96\n",
       "f1_score_macro                   0.95 0.96\n",
       "f1_score_micro                   0.95 0.96\n",
       "f1_score_weighted                0.95 0.96\n",
       "log_loss                         0.54 0.24\n",
       "norm_macro_recall                0.94 0.96\n",
       "precision_score_macro            0.95 0.96\n",
       "precision_score_micro            0.95 0.96\n",
       "precision_score_weighted         0.95 0.96\n",
       "recall_score_macro               0.95 0.96\n",
       "recall_score_micro               0.95 0.96\n",
       "recall_score_weighted            0.95 0.96\n",
       "weighted_accuracy                0.95 0.96"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "children = list(run.get_children())\n",
    "metricslist = {}\n",
    "for run in children:\n",
    "    properties = run.get_properties()\n",
    "    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}\n",
    "    metricslist[int(properties['iteration'])] = metrics\n",
    "\n",
    "rundata = pd.DataFrame(metricslist).sort_index(1)\n",
    "rundata"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "savitam"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
